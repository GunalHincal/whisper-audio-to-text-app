import streamlit as st
import whisper
import tempfile
import os
import json
import ffmpeg
import time
import torch
import io  # ğŸ”¥ Eklenen kÃ¼tÃ¼phane
import psutil  # ğŸ”¥ CPU KullanÄ±mÄ±nÄ± GÃ¶steren KÃ¼tÃ¼phane

# ğŸ›  CUDA OptimizasyonlarÄ±
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
torch.cuda.empty_cache()
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = False

# ğŸ“Š GPU KullanÄ±mÄ± Fonksiyonu
def get_gpu_usage():
    allocated = torch.cuda.memory_allocated() / 1024**3
    reserved = torch.cuda.memory_reserved() / 1024**3
    return allocated, reserved

# ğŸ“Š RAM KullanÄ±mÄ± Fonksiyonu
def get_ram_usage():
    return psutil.virtual_memory().percent

# ğŸ—ï¸ Sayfa YapÄ±landÄ±rmasÄ±
st.set_page_config(page_title="Whisper Ses Transkripsiyon", layout="centered")

# ğŸ¯ GPU KullanÄ±mÄ±nÄ± Sidebar'da GÃ¶ster
st.sidebar.header("ğŸ“Š GPU KullanÄ±mÄ±")
allocated, reserved = get_gpu_usage()
st.sidebar.write(f"ğŸ’¾ AyrÄ±lmÄ±ÅŸ Bellek: {allocated:.2f} GB")
st.sidebar.write(f"ğŸ”’ Rezerve Edilen Bellek: {reserved:.2f} GB")
st.sidebar.write(f"ğŸ–¥ï¸ RAM KullanÄ±mÄ±: {get_ram_usage():.2f}%")

# ğŸ“Œ **Ä°ÅŸlem Durumu iÃ§in Progress Bar**
progress_bar = st.sidebar.progress(0)
status_text = st.sidebar.empty()

st.title("ğŸ™ï¸ Ses veya Video DosyasÄ± YÃ¼kleyin ve Metne Ã‡evirin")

# ğŸ“Œ Ses DÃ¶nÃ¼ÅŸtÃ¼rme Fonksiyonu (FFmpeg ile)
def convert_to_wav(input_path):
    """ Ses veya video dosyasÄ±nÄ± WAV formatÄ±na Ã§evirir (FFmpeg kullanarak). """
    output_path = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name
    try:
        (
            ffmpeg
            .input(input_path)
            .output(output_path, format="wav", acodec="pcm_s16le", ac=1, ar="16000")
            .run(quiet=True, overwrite_output=True)
        )
        return output_path
    except Exception as e:
        st.error(f"âš ï¸ Ses dÃ¶nÃ¼ÅŸtÃ¼rme hatasÄ±: {e}")
        return None
    
# ğŸ“Œ **Transkripsiyon Fonksiyonu (Manuel Ä°lerleme GÃ¼ncellemesi ile)**
def transcribe_audio(audio_path, model):
    """ Whisper modeli ile transkripsiyon yapar ve ilerleme Ã§ubuÄŸunu manuel gÃ¼nceller. """
    result = model.transcribe(audio_path, fp16=False)
    total_segments = len(result["segments"])
    
    for i, _ in enumerate(result["segments"], start=1):
        progress_bar.progress(i / total_segments)
        time.sleep(0.1)  # GÃ¶rsel geri bildirim saÄŸlamak iÃ§in
    
    return result

# ğŸ“Œ **Manuel SRT DosyasÄ± Ãœreten Fonksiyon**
def generate_srt(segments):
    srt_content = ""
    for i, segment in enumerate(segments):
        start_time = segment["start"]
        end_time = segment["end"]
        text = segment["text"]

        # ğŸ•’ Zaman formatÄ±nÄ± (SRT formatÄ±na) Ã§evir
        start_srt = time.strftime("%H:%M:%S", time.gmtime(start_time)) + f",{int((start_time % 1) * 1000):03d}"
        end_srt = time.strftime("%H:%M:%S", time.gmtime(end_time)) + f",{int((end_time % 1) * 1000):03d}"

        srt_content += f"{i+1}\n{start_srt} --> {end_srt}\n{text}\n\n"

    return srt_content

# ğŸ“Œ Dosya YÃ¼kleme BileÅŸeni
uploaded_file = st.file_uploader(
    "Bir ses veya video dosyasÄ± yÃ¼kleyin (MP3, WAV, MP4, M4A, OGG, CAF, AAC, FLAC)",
    type=["mp3", "wav", "mp4", "m4a", "ogg", "caf", "aac", "flac"]
)

if uploaded_file is not None:
    st.audio(uploaded_file, format="audio/wav")

    # ğŸ“¥ GeÃ§ici dosyaya kaydet
    temp_audio_file = tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1])
    temp_audio_file.write(uploaded_file.read())
    temp_audio_file.close()

    # ğŸ¯ WAV formatÄ±na Ã§evir
    wav_filename = convert_to_wav(temp_audio_file.name)
    os.remove(temp_audio_file.name)

    if wav_filename:
        st.write("ğŸ”„ Ses dosyanÄ±z iÅŸleniyor, lÃ¼tfen bekleyin...")
        status_text.text("ğŸ”„ Transkripsiyon devam ediyor...")

        # ğŸ”„ Medium model kullan (VRAM optimizasyonu)
        whisper_model = whisper.load_model("medium").to("cuda")

        result = transcribe_audio(wav_filename, whisper_model)
        os.remove(wav_filename)

        if "text" in result:
            transcribed_text = result["text"]
            segments = result["segments"]

            # **ğŸ”¥ Debug: Segmentlerin iÃ§eriÄŸini terminale yaz**
            print("âœ… Segmentlerin Ä°Ã§eriÄŸi:")
            print(json.dumps(segments, indent=4, ensure_ascii=False))

            st.subheader("ğŸ“ Transkripsiyon Sonucu")
            st.text_area("Ã‡Ä±ktÄ±:", transcribed_text, height=250)

            json_output = json.dumps(segments, ensure_ascii=False, indent=4)

            # **ğŸ“ SRT DosyasÄ±nÄ± Manuel OluÅŸtur**
            srt_content = generate_srt(segments)

            # ğŸ” **Debug iÃ§in iÃ§eriÄŸi terminale yazdÄ±ralÄ±m**
            print("âœ… SRT DosyasÄ± Ä°Ã§eriÄŸi:")
            print(srt_content)

            # **EÄŸer dosya boÅŸsa hata mesajÄ± gÃ¶ster**
            if not srt_content.strip():
                st.error("âŒ Hata: OluÅŸturulan SRT dosyasÄ± boÅŸ!")
                print("âŒ DEBUG: SRT dosyasÄ± boÅŸ oluÅŸturuldu, segmentler kontrol edilmeli.")
            else:
                # âœ… **Streamlit butonlarÄ± ekleyelim**
                st.download_button("ğŸ“¥ JSON FormatÄ±nda Ä°ndir", json_output, file_name="transcription.json", mime="application/json")
                st.download_button("ğŸ“¥ DÃ¼z Metni Ä°ndir", transcribed_text, file_name="transcription.txt", mime="text/plain")
                
                # ğŸ”„ **BytesIO ile SRT DosyasÄ±nÄ± DoÄŸru Åekilde Ver**
                srt_buffer = io.BytesIO(srt_content.encode("utf-8"))
                st.download_button("ğŸ“¥ Zaman DamgalÄ± AltyazÄ± (SRT) Ä°ndir", srt_buffer, file_name="transcription.srt", mime="text/plain")
