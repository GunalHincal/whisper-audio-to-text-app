import os
import streamlit as st
import whisper
import tempfile
import json
import time
import torch
import io
import subprocess
from pydub import AudioSegment
from pydub.utils import which

# ğŸ—ï¸ **Sayfa YapÄ±landÄ±rmasÄ±**
st.set_page_config(page_title="Whisper Ses Transkripsiyon", layout="centered")
st.title("ğŸ™ï¸ Ses veya Video DosyasÄ± YÃ¼kleyin ve Metne Ã‡evirin")

# ğŸ”„ **FFmpeg ve FFprobe Yolunu TanÄ±mla**
ffmpeg_path = which("ffmpeg")
ffprobe_path = which("ffprobe")

# **FFmpeg Yolunu Manuel Olarak Ayarla (Windows Ä°Ã§in)**
if ffmpeg_path is None or ffprobe_path is None:
    os.environ["PATH"] += os.pathsep + "C:\\Program Files\\ffmpeg-7.1-essentials_build\\bin"

# Pydub'un FFmpeg kullanmasÄ±nÄ± saÄŸla
AudioSegment.converter = which("ffmpeg")
AudioSegment.ffmpeg = which("ffmpeg")
AudioSegment.ffprobe = which("ffprobe")

# ğŸ”„ **FFmpeg'in sistemde olup olmadÄ±ÄŸÄ±nÄ± kontrol et**
def is_ffmpeg_available():
    try:
        subprocess.run(["ffmpeg", "-version"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        subprocess.run(["ffprobe", "-version"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        return True
    except FileNotFoundError:
        return False

if not is_ffmpeg_available():
    st.error("âš ï¸ FFmpeg bulunamadÄ±! LÃ¼tfen sisteminize FFmpeg yÃ¼kleyin.")

# ğŸ›  **CUDA KullanÄ±labilirlik KontrolÃ¼**
device = "cuda" if torch.cuda.is_available() else "cpu"

# ğŸ“Œ **GPU KullanÄ±mÄ± Fonksiyonu**
def get_gpu_usage():
    if device == "cuda":
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        return allocated, reserved
    return 0, 0

# ğŸ¯ **GPU KullanÄ±mÄ±nÄ± Sidebar'da GÃ¶ster**
st.sidebar.header("ğŸ“Š GPU KullanÄ±mÄ±")
allocated, reserved = get_gpu_usage()
st.sidebar.write(f"ğŸ’¾ AyrÄ±lmÄ±ÅŸ Bellek: {allocated:.2f} GB")
st.sidebar.write(f"ğŸ”’ Rezerve Edilen Bellek: {reserved:.2f} GB")

# ğŸ“Œ **Ses DÃ¶nÃ¼ÅŸtÃ¼rme Fonksiyonu (FFmpeg ile)**
def convert_to_wav(input_path):
    output_path = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name
    try:
        subprocess.run(["ffmpeg", "-i", input_path, "-ac", "1", "-ar", "16000", output_path], 
                       stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        return output_path
    except Exception as e:
        st.error(f"âš ï¸ Ses dÃ¶nÃ¼ÅŸtÃ¼rme hatasÄ±: {e}")
        return None

# ğŸ“Œ **Transkripsiyon Fonksiyonu**
def transcribe_audio(audio_path, model):
    result = model.transcribe(audio_path, fp16=False)
    return result

# ğŸ“Œ **SRT DosyasÄ± Ãœreten Fonksiyon**
def generate_srt(segments):
    srt_content = ""
    for i, segment in enumerate(segments):
        start_time = segment["start"]
        end_time = segment["end"]
        text = segment["text"]

        # ğŸ•’ Zaman formatÄ±nÄ± (SRT formatÄ±na) Ã§evir
        start_srt = time.strftime("%H:%M:%S", time.gmtime(start_time)) + f",{int((start_time % 1) * 1000):03d}"
        end_srt = time.strftime("%H:%M:%S", time.gmtime(end_time)) + f",{int((end_time % 1) * 1000):03d}"

        srt_content += f"{i+1}\n{start_srt} --> {end_srt}\n{text}\n\n"

    return srt_content

# ğŸ“Œ **Dosya YÃ¼kleme BileÅŸeni**
uploaded_file = st.file_uploader(
    "Bir ses veya video dosyasÄ± yÃ¼kleyin (MP3, WAV, MP4, M4A, OGG, CAF, AAC, FLAC)",
    type=["mp3", "wav", "mp4", "m4a", "ogg", "caf", "aac", "flac"]
)

if uploaded_file is not None:
    st.audio(uploaded_file, format="audio/wav")

    # ğŸ“¥ GeÃ§ici dosyaya kaydet
    temp_audio_file = tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1])
    temp_audio_file.write(uploaded_file.read())
    temp_audio_file.close()

    # ğŸ¯ WAV formatÄ±na Ã§evir
    wav_filename = convert_to_wav(temp_audio_file.name)
    os.remove(temp_audio_file.name)

    if wav_filename:
        st.write("ğŸ”„ Ses dosyanÄ±z iÅŸleniyor, lÃ¼tfen bekleyin...")

        # ğŸ”„ **Medium model kullan ve GPU varsa ona yÃ¼kle**
        whisper_model = whisper.load_model("medium").to(device)

        result = transcribe_audio(wav_filename, whisper_model)
        os.remove(wav_filename)

        if "text" in result:
            transcribed_text = result["text"]
            segments = result["segments"]

            # **ğŸ”¥ Debug: Segmentlerin iÃ§eriÄŸini terminale yaz**
            print("âœ… Segmentlerin Ä°Ã§eriÄŸi:")
            print(json.dumps(segments, indent=4, ensure_ascii=False))

            st.subheader("ğŸ“ Transkripsiyon Sonucu")
            st.text_area("Ã‡Ä±ktÄ±:", transcribed_text, height=250)

            json_output = json.dumps(segments, ensure_ascii=False, indent=4)

            # **ğŸ“ SRT DosyasÄ±nÄ± Manuel OluÅŸtur**
            srt_content = generate_srt(segments)

            # ğŸ” **Debug iÃ§in iÃ§eriÄŸi terminale yazdÄ±ralÄ±m**
            print("âœ… SRT DosyasÄ± Ä°Ã§eriÄŸi:")
            print(srt_content)

            # **EÄŸer dosya boÅŸsa hata mesajÄ± gÃ¶ster**
            if not srt_content.strip():
                st.error("âŒ Hata: OluÅŸturulan SRT dosyasÄ± boÅŸ!")
                print("âŒ DEBUG: SRT dosyasÄ± boÅŸ oluÅŸturuldu, segmentler kontrol edilmeli.")
            else:
                # âœ… **Streamlit butonlarÄ± ekleyelim**
                st.download_button("ğŸ“¥ JSON FormatÄ±nda Ä°ndir", json_output, file_name="transcription.json", mime="application/json")
                st.download_button("ğŸ“¥ DÃ¼z Metni Ä°ndir", transcribed_text, file_name="transcription.txt", mime="text/plain")
                
                # ğŸ”„ **BytesIO ile SRT DosyasÄ±nÄ± DoÄŸru Åekilde Ver**
                srt_buffer = io.BytesIO(srt_content.encode("utf-8"))
                st.download_button("ğŸ“¥ Zaman DamgalÄ± AltyazÄ± (SRT) Ä°ndir", srt_buffer, file_name="transcription.srt", mime="text/plain")
